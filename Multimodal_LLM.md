1. Transformer升级之路：17、多模态编码位置的简单思考 https://kexue.fm/archives/10040
![image](https://github.com/qianxinchun/awesomeLLMTopics/assets/7309139/fbfe50a9-054a-47d8-af67-408e2958247a)

2. “闭门造车”之多模态模型方案浅谈 https://kexue.fm/archives/9984
![image](https://github.com/qianxinchun/awesomeLLMTopics/assets/7309139/ae424930-37fd-4199-a937-76dfe8379167)


3. 在用llava架构训vlm时，llm基模选择base模型好还是chat模型好呢？ https://www.zhihu.com/question/650838721/answer/3448817012


